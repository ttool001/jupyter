{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------+-------+-----+------+------+-------+----+----------+-------+------------+----------+-------+--------+--------------+----+\n",
      "|dofM|dofW|carrier|tailnum|flnum|org_id|origin|dest_id|dest|crsdeptime|deptime|depdelaymins|crsarrtime|arrtime|arrdelay|crselapsedtime|dist|\n",
      "+----+----+-------+-------+-----+------+------+-------+----+----------+-------+------------+----------+-------+--------+--------------+----+\n",
      "|   1|   3|     AA| N338AA|    1| 12478|   JFK|  12892| LAX|     900.0|  914.0|        14.0|    1225.0| 1238.0|    13.0|         385.0|2475|\n",
      "|   2|   4|     AA| N338AA|    1| 12478|   JFK|  12892| LAX|     900.0|  857.0|         0.0|    1225.0| 1226.0|     1.0|         385.0|2475|\n",
      "+----+----+-------+-------+-----+------+------+-------+----+----------+-------+------------+----------+-------+--------+--------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def build_schema():\n",
    "    \"\"\"Build and return a schema to use for the sample data.\"\"\"\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"dofM\", StringType(), True),\n",
    "            StructField(\"dofW\", StringType(), True),\n",
    "            StructField(\"carrier\", StringType(), True),\n",
    "            StructField(\"tailnum\", StringType(), True),\n",
    "            StructField(\"flnum\", IntegerType(), True),\n",
    "            StructField(\"org_id\", StringType(), True),\n",
    "            StructField(\"origin\", StringType(), True),\n",
    "            StructField(\"dest_id\", StringType(), True),\n",
    "            StructField(\"dest\", StringType(), True),\n",
    "            StructField(\"crsdeptime\", DoubleType(), True),\n",
    "            StructField(\"deptime\", DoubleType(), True),\n",
    "            StructField(\"depdelaymins\", DoubleType(), True),\n",
    "            StructField(\"crsarrtime\", DoubleType(), True),\n",
    "            StructField(\"arrtime\", DoubleType(), True),\n",
    "            StructField(\"arrdelay\", DoubleType(), True),\n",
    "            StructField(\"crselapsedtime\", DoubleType(), True),\n",
    "            StructField(\"dist\", IntegerType(), True),\n",
    "        ]\n",
    "    )\n",
    "    return schema\n",
    "\n",
    "#load data from csv and create DF\n",
    "df = spark.read.csv(\n",
    "    \"/mnt/d/dev/sparkExample/data/rita2014jan.csv\", header=False, mode=\"DROPMALFORMED\", schema=build_schema() \n",
    ")\n",
    "\n",
    "df.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dofM: string (nullable = true)\n",
      " |-- dofW: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flnum: integer (nullable = true)\n",
      " |-- org_id: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest_id: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- crsdeptime: double (nullable = true)\n",
      " |-- deptime: double (nullable = true)\n",
      " |-- depdelaymins: double (nullable = true)\n",
      " |-- crsarrtime: double (nullable = true)\n",
      " |-- arrtime: double (nullable = true)\n",
      " |-- arrdelay: double (nullable = true)\n",
      " |-- crselapsedtime: double (nullable = true)\n",
      " |-- dist: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rename default column name - this vs passing in schema?\n",
    "df.printSchema()\n",
    "#df = df.toDF(dofM: String, dofW: String, carrier: String, tailnum: String, flnum: Int, org_id: String, origin: String, dest_id: String, dest: String, crsdeptime: Double, deptime: Double, depdelaymins: Double, crsarrtime: Double, arrtime: Double, arrdelay: Double, crselapsedtime: Double, dist: Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+\n",
      "|dist|dest_id|dofM|dest_index|depdelaymins|tailnum_index|crselapsedtime|org_id|arrdelay|deptime|flnum|origin_index|crsarrtime|carrier_index|arrtime|crsdeptime|dofW|\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+\n",
      "|2475|  12892|   1|       2.0|        14.0|       3511.0|         385.0| 12478|    13.0|  914.0|    1|        18.0|    1225.0|          4.0| 1238.0|     900.0|   3|\n",
      "|2475|  12892|   2|       2.0|         0.0|       3511.0|         385.0| 12478|     1.0|  857.0|    1|        18.0|    1225.0|          4.0| 1226.0|     900.0|   4|\n",
      "|2475|  12892|   4|       2.0|        65.0|       4088.0|         385.0| 12478|    59.0| 1005.0|    1|        18.0|    1225.0|          4.0| 1324.0|     900.0|   6|\n",
      "|2475|  12892|   5|       2.0|       110.0|       3974.0|         385.0| 12478|   110.0| 1050.0|    1|        18.0|    1225.0|          4.0| 1415.0|     900.0|   7|\n",
      "|2475|  12892|   6|       2.0|        17.0|       3727.0|         385.0| 12478|     0.0|  917.0|    1|        18.0|    1225.0|          4.0| 1217.0|     900.0|   1|\n",
      "|2475|  12892|   7|       2.0|        10.0|       3659.0|         385.0| 12478|     0.0|  910.0|    1|        18.0|    1225.0|          4.0| 1212.0|     900.0|   2|\n",
      "|2475|  12892|   8|       2.0|        23.0|       3974.0|         385.0| 12478|     0.0|  923.0|    1|        18.0|    1225.0|          4.0| 1215.0|     900.0|   3|\n",
      "|2475|  12892|   9|       2.0|         0.0|       3532.0|         385.0| 12478|     0.0|  859.0|    1|        18.0|    1225.0|          4.0| 1204.0|     900.0|   4|\n",
      "|2475|  12892|  10|       2.0|        29.0|       3727.0|         385.0| 12478|    20.0|  929.0|    1|        18.0|    1225.0|          4.0| 1245.0|     900.0|   5|\n",
      "|2475|  12892|  11|       2.0|        15.0|       3659.0|         385.0| 12478|    79.0|  915.0|    1|        18.0|    1225.0|          4.0| 1344.0|     900.0|   6|\n",
      "|2475|  12892|  12|       2.0|         0.0|       3511.0|         385.0| 12478|     0.0|  854.0|    1|        18.0|    1225.0|          4.0| 1208.0|     900.0|   7|\n",
      "|2475|  12892|  13|       2.0|         0.0|       3565.0|         385.0| 12478|     0.0|  855.0|    1|        18.0|    1225.0|          4.0| 1152.0|     900.0|   1|\n",
      "|2475|  12892|  14|       2.0|         0.0|       3532.0|         385.0| 12478|     0.0|  853.0|    1|        18.0|    1225.0|          4.0| 1144.0|     900.0|   2|\n",
      "|2475|  12892|  15|       2.0|         0.0|       3939.0|         385.0| 12478|     0.0|  851.0|    1|        18.0|    1225.0|          4.0| 1201.0|     900.0|   3|\n",
      "|2475|  12892|  16|       2.0|         0.0|       3768.0|         385.0| 12478|     0.0|  856.0|    1|        18.0|    1225.0|          4.0| 1216.0|     900.0|   4|\n",
      "|2475|  12892|  17|       2.0|         0.0|       3768.0|         385.0| 12478|     0.0|  855.0|    1|        18.0|    1225.0|          4.0| 1154.0|     900.0|   5|\n",
      "|2475|  12892|  18|       2.0|         0.0|       3768.0|         385.0| 12478|     0.0|  854.0|    1|        18.0|    1225.0|          4.0| 1156.0|     900.0|   6|\n",
      "|2475|  12892|  19|       2.0|         0.0|       3939.0|         385.0| 12478|     0.0|  858.0|    1|        18.0|    1225.0|          4.0| 1152.0|     900.0|   7|\n",
      "|2475|  12892|  20|       2.0|         0.0|       3768.0|         385.0| 12478|     0.0|  855.0|    1|        18.0|    1225.0|          4.0| 1209.0|     900.0|   1|\n",
      "|2475|  12892|  21|       2.0|         0.0|       3768.0|         385.0| 12478|     4.0|  858.0|    1|        18.0|    1225.0|          4.0| 1229.0|     900.0|   2|\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "#indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(df.columns)-set(['date'])) ]\n",
    "\n",
    "#convert columns with string value to int index value\n",
    "col_convert = ['carrier', 'tailnum', 'origin', 'dest']\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in col_convert ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(df).transform(df)\n",
    "\n",
    "df = df_r.select(list(set(df_r.columns) - set(col_convert)))\n",
    "\n",
    "df.show(20)\n",
    "#df_r.select('dofM', 'dofM_index', 'carrier', 'carrier_index', 'tailnum', 'tailnum_index').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|depdelaymins|delayed|\n",
      "+------------+-------+\n",
      "|        14.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|        65.0|    1.0|\n",
      "|       110.0|    1.0|\n",
      "|        17.0|    0.0|\n",
      "|        10.0|    0.0|\n",
      "|        23.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|        29.0|    0.0|\n",
      "|        15.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "|         0.0|    0.0|\n",
      "+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_r = df.withColumn('delayed', when(df.depdelaymins > 40, 1.0).otherwise(0.0))\n",
    "df_r.select('depdelaymins', 'delayed').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "inDfCols = df_r.columns\n",
    "df_r = df_r.select(*(col(c).cast('int').alias(c) for c in inDfCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dist: integer (nullable = true)\n",
      " |-- dest_id: integer (nullable = true)\n",
      " |-- dofM: integer (nullable = true)\n",
      " |-- dest_index: integer (nullable = true)\n",
      " |-- depdelaymins: integer (nullable = true)\n",
      " |-- tailnum_index: integer (nullable = true)\n",
      " |-- crselapsedtime: integer (nullable = true)\n",
      " |-- org_id: integer (nullable = true)\n",
      " |-- arrdelay: integer (nullable = true)\n",
      " |-- deptime: integer (nullable = true)\n",
      " |-- flnum: integer (nullable = true)\n",
      " |-- origin_index: integer (nullable = true)\n",
      " |-- crsarrtime: integer (nullable = true)\n",
      " |-- carrier_index: integer (nullable = true)\n",
      " |-- arrtime: integer (nullable = true)\n",
      " |-- crsdeptime: integer (nullable = true)\n",
      " |-- dofW: integer (nullable = true)\n",
      " |-- delayed: integer (nullable = true)\n",
      "\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+-------+\n",
      "|dist|dest_id|dofM|dest_index|depdelaymins|tailnum_index|crselapsedtime|org_id|arrdelay|deptime|flnum|origin_index|crsarrtime|carrier_index|arrtime|crsdeptime|dofW|delayed|\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+-------+\n",
      "|  31|  14256|   1|       269|          21|         1315|            26| 15841|      20|   1101|   65|         260|      1106|            9|   1126|      1040|   3|      0|\n",
      "|  31|  14256|   2|       269|           0|          871|            26| 15841|       0|   1019|   65|         260|      1106|            9|   1039|      1040|   4|      0|\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "We have 309565 training examples and 132057 test examples.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset randomly into 70% for training and 30% for testing.\n",
    "trainingData, testData = df_r.randomSplit([0.7, 0.3])\n",
    "trainingData.printSchema()\n",
    "trainingData.show(2)\n",
    "print \"We have %d training examples and %d test examples.\" % (trainingData.count(), testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "featuresCols = df_r.columns\n",
    "featuresCols.remove('delayed')\n",
    "# This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\n",
    "vectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n",
    "# This identifies categorical features and indexes them.\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "vectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"indexedFeatures\", maxCategories=4)\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"delayed\", outputCol=\"indexedLabel\").fit(df_r)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df_r.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, vectorAssembler, vectorIndexer, dt])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers. This takes time\n",
    "model = pipeline.fit(trainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|prediction|indexedLabel|\n",
      "+----------+------------+\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "|       1.0|         1.0|\n",
      "|       0.0|         0.0|\n",
      "|       0.0|         0.0|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Error = 0.0118171 \n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4dbbb647fff10c12c7ae) of depth 5 with 19 nodes\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"indexedLabel\").show(20)\n",
    "\n",
    "'''\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "'''\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "#print the stage of pipe 3 is the model\n",
    "treeModel = model.stages[3]\n",
    "# summary only\n",
    "print(treeModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+-------+\n",
      "|dist|dest_id|dofM|dest_index|depdelaymins|tailnum_index|crselapsedtime|org_id|arrdelay|deptime|flnum|origin_index|crsarrtime|carrier_index|arrtime|crsdeptime|dofW|delayed|\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+-------+\n",
      "|  31|  14256|   2|       269|           0|          871|            26| 15841|       0|   1019|   65|         260|      1106|            9|   1039|      1040|   4|      0|\n",
      "|  31|  14256|  10|       269|           0|         3824|            26| 15841|       0|   1024|   65|         260|      1106|            9|   1046|      1040|   5|      0|\n",
      "+----+-------+----+----------+------------+-------------+--------------+------+--------+-------+-----+------------+----------+-------------+-------+----------+----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
